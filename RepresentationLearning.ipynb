{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "ycNqw0jQJESY"
      },
      "source": [
        "# CS231a PSET 3 Problem 2: Representation Learning with Self-Supervised Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "uDyejdg_JESZ"
      },
      "source": [
        "# Overview\n",
        "\n",
        "In this notebook we will be using the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), a variation on the classic [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database), to showcase how self-supervised representation learning can be utilized for more efficient training in downstream tasks. We will do the following things:\n",
        "\n",
        "1. Train a classifier from scratch on the Fashion MNIST dataset and observe how fast and well it learns.\n",
        "\n",
        "2. Train useful representations via predicting image rotations, rather than classifying clothing types.\n",
        "\n",
        "3. Transfer our rotation pretraining features to solve the classification task with much less data than in step 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eUWNACtH46V"
      },
      "source": [
        "First, you should upload the files in 'code/p2' directory onto a location of your choosing in Drive and run the following to have access to them. You can also skip this step and just upload the files directly using the files tab, though any changes you make will be gone if you close the tab or the colab runtime ends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IcaTRbE5mk6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Enter the foldername in your Drive where you have saved the unzipped\n",
        "# '.py' files from the p2 folder\n",
        "# e.g. 'cs231a/pset3/p2'\n",
        "FOLDERNAME = 'cs231a/pset3/p2'\n",
        "\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "%cd drive/My\\ Drive\n",
        "%cd $FOLDERNAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s1oXQMCeV72"
      },
      "source": [
        "You should now be able to click on the folder icon to the left and see a folder that says 'drive' above a folder that says 'sample_data'. Open it, go to MyDrive, and then navigate to where you put the files. You can double click on any .py file to modify it within this Colab notebook, and we recommend you work on these problems using that. Let's confirm the files are uploaded and accessible:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11dNVlk9on-h"
      },
      "outputs": [],
      "source": [
        "import import_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4lEsdVToylL"
      },
      "source": [
        "If the above import of works, you are ready to get going with the rest of this problem! Before that, let's make sure you allocate a GPU so that code runs faster: click Runtime -> Change runtime type -> Hardware Accelerator -> GPU and your Colab instance will automatically be backed by GPU compute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "P-iAbOZEJESg"
      },
      "source": [
        "# Fashion MNIST Data Preparation\n",
        "\n",
        "First, let's get the data prepared. Luckily, PyTorch has a handy function to download it for us in its [torchvision.datasets](https://pytorch.org/docs/stable/torchvision/datasets.html#cifar) package. Go ahead and get the \n",
        "required torchvision version by running the following; you'll only need to do so once, and then click Runtime->Restart runtime to move on. Every time you restart the runtime, you'll need to re-run everything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TKwIqyhcdttz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchvision==0.2.2.post3\n",
            "  Downloading torchvision-0.2.2.post3-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/envs/openteach/lib/python3.10/site-packages (from torchvision==0.2.2.post3) (1.26.4)\n",
            "Requirement already satisfied: six in /opt/homebrew/Caskroom/miniconda/base/envs/openteach/lib/python3.10/site-packages (from torchvision==0.2.2.post3) (1.16.0)\n",
            "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniconda/base/envs/openteach/lib/python3.10/site-packages (from torchvision==0.2.2.post3) (2.4.0.dev20240316)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/openteach/lib/python3.10/site-packages (from torchvision==0.2.2.post3) (10.1.0)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/envs/openteach/lib/python3.10/site-packages (from torch->torchvision==0.2.2.post3) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/Caskroom/miniconda/base/envs/openteach/lib/python3.10/site-packages (from torch->torchvision==0.2.2.post3) (4.9.0)\n",
            "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniconda/base/envs/openteach/lib/python3.10/site-packages (from torch->torchvision==0.2.2.post3) (1.12)\n",
            "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniconda/base/envs/openteach/lib/python3.10/site-packages (from torch->torchvision==0.2.2.post3) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/openteach/lib/python3.10/site-packages (from torch->torchvision==0.2.2.post3) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /opt/homebrew/Caskroom/miniconda/base/envs/openteach/lib/python3.10/site-packages (from torch->torchvision==0.2.2.post3) (2024.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/openteach/lib/python3.10/site-packages (from jinja2->torch->torchvision==0.2.2.post3) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Caskroom/miniconda/base/envs/openteach/lib/python3.10/site-packages (from sympy->torch->torchvision==0.2.2.post3) (1.3.0)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'torchvision' candidate (version 0.2.2.post3 at https://files.pythonhosted.org/packages/fb/01/03fd7e503c16b3dc262483e5555ad40974ab5da8b9879e164b56c1f4ef6f/torchvision-0.2.2.post3-py2.py3-none-any.whl (from https://pypi.org/simple/torchvision/))\n",
            "Reason for being yanked: So that users won't accidentally install this when using python 3.11\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading torchvision-0.2.2.post3-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.0.dev20240316\n",
            "    Uninstalling torchvision-0.18.0.dev20240316:\n",
            "      Successfully uninstalled torchvision-0.18.0.dev20240316\n",
            "Successfully installed torchvision-0.2.2.post3\n",
            "Collecting Pillow==6.1.0\n",
            "  Downloading Pillow-6.1.0.tar.gz (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: Pillow\n",
            "  Building wheel for Pillow (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for Pillow: filename=Pillow-6.1.0-cp310-cp310-macosx_11_0_arm64.whl size=496706 sha256=c3f62e7d5bf643c7bd0a41955affe8aadf385673615a9d76e48af7d6ba30b044\n",
            "  Stored in directory: /Users/krishnans/Library/Caches/pip/wheels/22/07/d1/ff10d296cf2bc6d748ece7599e9a7433b34378ed5259106303\n",
            "Successfully built Pillow\n",
            "Installing collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 10.1.0\n",
            "    Uninstalling Pillow-10.1.0:\n",
            "      Successfully uninstalled Pillow-10.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.34.0 requires pillow>=8.3.2, but you have pillow 6.1.0 which is incompatible.\n",
            "matplotlib 3.5.3 requires pillow>=6.2.0, but you have pillow 6.1.0 which is incompatible.\n",
            "scikit-image 0.23.1 requires pillow>=9.1, but you have pillow 6.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-6.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision==0.2.2.post3 -U #need this version to get processed data\n",
        "!pip install Pillow==6.1.0 -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzZ-y8pDeCvh"
      },
      "source": [
        "Now we can go ahead and get the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:49:22.731116Z",
          "start_time": "2020-03-23T16:49:22.710079Z"
        },
        "hidden": true,
        "id": "swy9dHIqJESg"
      },
      "outputs": [],
      "source": [
        "# Download Fashion MNIST dataset from PyTorch \n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                              transforms.Resize((32,32)),\n",
        "                              transforms.ToTensor(),\n",
        "                              ])\n",
        "PATH_TO_STORE_DATA = 'problem2/data/'\n",
        "dataset_train = torchvision.datasets.FashionMNIST(PATH_TO_STORE_DATA, download=True, train=True, \n",
        "                                             transform=transform)\n",
        "dataset_test = torchvision.datasets.FashionMNIST(PATH_TO_STORE_DATA, download=True, train=False, \n",
        "                                            transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxmz5akRjg2W"
      },
      "source": [
        "Now that we have downloaded the data, we will implement a PyTorch [Dataset](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) so that we can load subsets of the full Fashion MNIST dataset and use either clothing type or image rotation as the label for a given image. Fill in the requisite bits of code in data.py marked with TODO (you can either do so directly through the file explorer on the left or do so locally and re-upload it), and try to execute the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ3Ojrcvjfj-"
      },
      "outputs": [],
      "source": [
        "from importlib import reload  \n",
        "import data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqDY5XfFmHvo"
      },
      "source": [
        "Now, let's create an instance of this Dataset for training Fashion MNIST  classification. We will create two versions of the training dataset, one with all the data and one with a small subset. If you have bugs in your code, simply modify data.py and re-run this bit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87wqQ88yxnSm"
      },
      "outputs": [],
      "source": [
        "data = reload(data) #reload for making changes during debugging\n",
        "train_full_dataset = data.MNISTDatasetWrapper(dataset_train, pct=1.0)\n",
        "test_full_dataset = data.MNISTDatasetWrapper(dataset_test, pct=1.0)\n",
        "print('Full dataset: {0} Training Samples | {1} Test Samples'.format(\n",
        "    len(train_full_dataset), len(test_full_dataset)))\n",
        "\n",
        "train_small_dataset = data.MNISTDatasetWrapper(dataset_train, pct=0.05)\n",
        "print('Small train dataset: {0} Training Samples'.format(len(train_small_dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC323C3768BK"
      },
      "source": [
        "Let's use the handy show_batch function to get an idea of what's in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn9mJMLR7AUU"
      },
      "outputs": [],
      "source": [
        "train_full_dataset.show_batch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "gAOwwDckJESZ"
      },
      "source": [
        "# PyTorch Vision Model\n",
        "\n",
        "Next, we need to define our neural net architectures for training on the data. Because we want to ultimately train for two objectives (clothing type classification and rotation classification), we will do this via several classes so that the weights gotten from representation learning can be re-used later for more efficient clothing classification.\n",
        "Fill in the marked portions of models.py, and try to execute the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:49:22.659560Z",
          "start_time": "2020-03-23T16:49:22.655226Z"
        },
        "hidden": true,
        "id": "ucYL8j4fJESb"
      },
      "outputs": [],
      "source": [
        "import models\n",
        "models = reload(models) #reload for making changes during debugging\n",
        "\n",
        "image_embed_net = models.ImageEmbedNet().cuda()\n",
        "classify_net = models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = models.ImageClassifyModel(image_embed_net, classify_net)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afWQLrriqcu7"
      },
      "source": [
        "If running the above results in errors, revise your code in models.py and re-run as before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSy0y-7zk5Jz"
      },
      "source": [
        "# Training for Fashion MNIST Class Prediction\n",
        "\n",
        "Let's now implement a method for training on the dataset with the model we defined above. We will create a re-usable function that can be used for both representation learning and learning to classify Fashion MNIST images. This will involve the following:\n",
        "*   Given the dataset, creating a PyTorch [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) which can take care of shuffling the dataset as well as combining multiple image.\n",
        "*   Creating a PyTorch loss function that can be used for optimizing our model for the task of classification. We will use the standard [Cross Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
        "*   Creating a PyTorch [optimizer](https://pytorch.org/docs/stable/optim.html) to update the weights of the model given the loss computation.\n",
        "*   Lastly, our two training loops (one for the number of epochs, and one for iterating over the dataset) in which we use all the above to train the model.\n",
        "\n",
        "Fill in the relevant portions of code in training.py, and try to execute the following to go ahead and train on the Fashion MNIST classification task. If training.py is finished, we now just need to call its train function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CDqWDBGzn1L"
      },
      "outputs": [],
      "source": [
        "import training\n",
        "\n",
        "training = reload(training)\n",
        "# Create fresh model before every run to make sure we start from scratch\n",
        "image_embed_net = models.ImageEmbedNet().cuda()\n",
        "classify_net = models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = models.ImageClassifyModel(image_embed_net, \n",
        "                                                          classify_net)\n",
        "\n",
        "training.train(train_full_dataset, mnist_classify_model, 16, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTETMWRO5xIg"
      },
      "source": [
        "You should get training accuracy of around 0.92. With the model now trained, let's implement a test function and call it to see how well it works on the test set. Finish the marked portions in testing.py and run the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOW9HX8N5SSt"
      },
      "outputs": [],
      "source": [
        "import testing\n",
        "\n",
        "testing = reload(testing)\n",
        "testing.test(test_full_dataset, mnist_classify_model, 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfGZfDvX6Xwh"
      },
      "source": [
        "You should get test set accuracy slighty lower than the train set accuracy. The accuracy is not great; on such simple data it should be fairly easy to get close to perfect accuracy. We'll try to address this with representation learning.\n",
        "\n",
        "Before that, let's try training on the smaller train set, and see how well the model can work on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoL5ycTp7NMb"
      },
      "outputs": [],
      "source": [
        "image_embed_net = models.ImageEmbedNet().cuda()\n",
        "classify_net = models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = models.ImageClassifyModel(image_embed_net, classify_net)\n",
        "training.train(train_small_dataset, mnist_classify_model, 16, 10)\n",
        "testing.test(test_full_dataset, mnist_classify_model, 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLCi6S2qvFyi"
      },
      "source": [
        "You should get both lower training and testing accuracy, since we are not training with much less data. If we iterate over the data for more epochs it is possible to get better results, but still below the accuracy gotten with the full dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "YItknfArJESi"
      },
      "source": [
        "# Representation Learning via Rotation Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:28:42.437483Z",
          "start_time": "2020-03-23T16:28:42.431824Z"
        },
        "hidden": true,
        "id": "uDYBx88AJESh"
      },
      "source": [
        "Now, let's define new datasets for doing our representation learning by predicting the rotation of Fashion MNIST images, and once again call show_batch to get a look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:49:23.193640Z",
          "start_time": "2020-03-23T16:49:22.790204Z"
        },
        "hidden": true,
        "id": "9qzZrVKtJESi"
      },
      "outputs": [],
      "source": [
        "data = reload(data) #reload for making changes during debugging\n",
        "\n",
        "train_rotation_dataset = data.MNISTDatasetWrapper(dataset_train, \n",
        "                                          pct=1.0, for_rotation_classification=True)\n",
        "test_rotation_dataset = data.MNISTDatasetWrapper(dataset_test, \n",
        "                                         pct=1.0, for_rotation_classification=True)\n",
        "train_rotation_dataset.show_batch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Ca8WNHxRJESj"
      },
      "source": [
        "Now, let's train a model on the rotation prediction task by once again using our train function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:50:25.874982Z",
          "start_time": "2020-03-23T16:50:25.871423Z"
        },
        "hidden": true,
        "id": "Qv5IDvkrJESj"
      },
      "outputs": [],
      "source": [
        "rotation_image_embed_net = models.ImageEmbedNet().cuda()\n",
        "rotation_classify_net = models.ClassifyNet(8).cuda()\n",
        "mnist_rotation_classify_model = models.ImageClassifyModel(rotation_image_embed_net, \n",
        "                                                   rotation_classify_net)\n",
        "training.train(train_rotation_dataset, mnist_rotation_classify_model, 16, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF4LGZASgQvl"
      },
      "source": [
        "As you should see, the network manages to get quite good at predicting rotations, with around 0.98 accuracy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkw_gKCjwpMc"
      },
      "source": [
        "We should once again get testing accuracy similar to training accuracy (around 0.98):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVSzgPLf-LI_"
      },
      "outputs": [],
      "source": [
        "testing.test(test_rotation_dataset, mnist_rotation_classify_model, 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "vMiIE-BfJESk"
      },
      "source": [
        "# Fine-Tuning for Fashion MNIST classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "lqZ3R7SiJESk"
      },
      "source": [
        "Now that we have pretrained our model on the rotation prediction task, let's reuse the image embed part of it to train it for the task of class classification. We will use load_state_dict to transfer over the weights from the trained model to a new instance of it, so we can later re-use the same representation learning weights in a different setup. Let's first try it on the full dataset and see how fast it converges compared to when we did not pretrain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-23T16:50:25.924413Z",
          "start_time": "2020-03-23T16:50:25.893074Z"
        },
        "hidden": true,
        "id": "Z96Vg9ruJESk"
      },
      "outputs": [],
      "source": [
        "image_embed_net = models.ImageEmbedNet().cuda()\n",
        "image_embed_net.load_state_dict(rotation_image_embed_net.state_dict())\n",
        "classify_net = models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = models.ImageClassifyModel(image_embed_net, classify_net)\n",
        "training.train(train_full_dataset, mnist_classify_model, 16, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMYyWBz--Itv"
      },
      "outputs": [],
      "source": [
        "testing.test(test_full_dataset, mnist_classify_model, 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwibJb2X80xK"
      },
      "source": [
        "As we can see, it improves faster and achieves better train and test performance, although the improvement is not huge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o03jVgO-crj"
      },
      "source": [
        "Now, let's try training with the small dataset again and see how well that works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDanA7ls-cB_"
      },
      "outputs": [],
      "source": [
        "image_embed_net = models.ImageEmbedNet().cuda()\n",
        "image_embed_net.load_state_dict(rotation_image_embed_net.state_dict())\n",
        "classify_net = models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = models.ImageClassifyModel(image_embed_net, classify_net)\n",
        "training.train(train_small_dataset, mnist_classify_model, 16, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP15EZYv9uxN"
      },
      "outputs": [],
      "source": [
        "testing.test(test_full_dataset, mnist_classify_model, 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL2YmOSM9E6E"
      },
      "source": [
        "Now we can see that the with the smaller dataset the pretrained features make a lot of difference, as we get a substantial improvement in training and test accuracy! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFp_O553ypvD"
      },
      "source": [
        "What if we just train for longer? With such a small training dataset, it's possible to achieve perfect accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoXnGifRypG1"
      },
      "outputs": [],
      "source": [
        "image_embed_net = models.ImageEmbedNet().cuda()\n",
        "image_embed_net.load_state_dict(rotation_image_embed_net.state_dict())\n",
        "classify_net = models.ClassifyNet(10).cuda()\n",
        "mnist_classify_model = models.ImageClassifyModel(image_embed_net, classify_net)\n",
        "training.train(train_small_dataset, mnist_classify_model, 16, 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEW6eFn99xEH"
      },
      "outputs": [],
      "source": [
        "testing.test(test_full_dataset, mnist_classify_model, 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNMUbGqh_AJr"
      },
      "source": [
        "As we can see, while training for longer on the small dataset gets perfect train accuracy, the test accuracy is no better than what we got before. Part of the benefit of having pre-trained features is greater robustness to this sort of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "oK7GsCQsJESm"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "That's it, you are done! Remember to submit your code by .py files to the autograder.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRqgNjfJSZiT"
      },
      "source": [
        "Credits: Aspects of this notebook have been adapted from [here](https://colab.research.google.com/github/AmarSaini/Epoching-Blog/blob/master/_notebooks/2020-03-23-Self-Supervision-with-FastAI.ipynb#scrollTo=lsQmOOQsMVFT)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
